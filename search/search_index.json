{
    "docs": [
        {
            "location": "/",
            "text": "Docker Scaler\n\u00b6\n\n\nThe goal of the \nDocker Scaler\n project is to provide a REST HTTP interface to scale services and nodes. It sends scaling alerts to \nAlertmanager\n which can be configured to notify you through email, Slack, etc.\n\n\nDocker Scaler\n examples can be found in the \nTutorials\n section located in the left-hand menu.",
            "title": "Home"
        },
        {
            "location": "/#docker-scaler",
            "text": "The goal of the  Docker Scaler  project is to provide a REST HTTP interface to scale services and nodes. It sends scaling alerts to  Alertmanager  which can be configured to notify you through email, Slack, etc.  Docker Scaler  examples can be found in the  Tutorials  section located in the left-hand menu.",
            "title": "Docker Scaler"
        },
        {
            "location": "/usage/",
            "text": "Usage\n\u00b6\n\n\nDocker Scaler\n is controlled by sending HTTP requests. Work in progress.\n\n\nScaling Services\n\u00b6\n\n\nScaling Nodes\n\u00b6\n\n\nAWS\n\u00b6",
            "title": "Usage"
        },
        {
            "location": "/usage/#usage",
            "text": "Docker Scaler  is controlled by sending HTTP requests. Work in progress.",
            "title": "Usage"
        },
        {
            "location": "/usage/#scaling-services",
            "text": "",
            "title": "Scaling Services"
        },
        {
            "location": "/usage/#scaling-nodes",
            "text": "",
            "title": "Scaling Nodes"
        },
        {
            "location": "/usage/#aws",
            "text": "",
            "title": "AWS"
        },
        {
            "location": "/service-scale/",
            "text": "Auto-Scaling With Docker Scaler And Instrumented Metrics\n\u00b6\n\n\nDocker Scaler\n provides an alternative to using Jenkins for service scaling shown in Docker Flow Monitor's \nauto-scaling tutorial\n. In this tutorial, we will construct a system that will scale a service based on response time. The following is an overview of the triggered events in our self-adapting system:\n\n\n\n\nThe \ngo-demo\n service response times becomes too high.\n\n\nDocker Flow Monitor\n is querying the services' metrics, notices the high response times, and alerts the \nAlertmanager\n.\n\n\nThe Alertmanager is configured to forward the alert to \nDocker Scaler\n.\n\n\nDocker Scaler\n scales the service up.\n\n\n\n\nThis tutorial assumes you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.\n\n\n\n\nInfo\n\n\nIf you are a Windows user, please run all the examples from \nGit Bash\n (installed through \nDocker for Windows\n). Also, make sure that your Git client is configured to check out the code \nAS-IS\n. Otherwise, Windows might change carriage returns to the Windows format.\n\n\n\n\nSetting Up A Cluster\n\u00b6\n\n\n\n\nInfo\n\n\nFeel free to skip this section if you already have a Swarm cluster that can be used for this tutorial\n\n\n\n\nWe'll create a Swarm cluster consisting of three nodes created with Docker Machine.\n\n\ngit clone https://github.com/thomasjpfan/docker-scaler.git\n\n\ncd\n docker-scaler\n\n./scripts/ds-swarm.sh\n\n\neval\n \n$(\ndocker-machine env swarm-1\n)\n\n\n\n\n\nWe cloned the \nthomasjpfan/docker-scaler\n respository. It contains all the scripts and stack files we will use throughout this tutorial. Next, we executed the \nds-swarm.sh\n script that created the cluster. Finally, we used the \neval\n command to tell our local Docker client to use the remote Docker Engine \nswarm-1\n.\n\n\nDeploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)\n\u00b6\n\n\nFor convenience, we will use \nDocker Flow Proxy\n and \nDocker Flow Swarm Listener\n to get a single access point to the cluster.\n\n\ndocker network create -d overlay proxy\n\ndocker stack deploy \n\\\n\n    -c stacks/docker-flow-proxy-mem.yml \n\\\n\n    proxy\n\n\n\n\nPlease visit \nproxy.dockerflow.com\n and \nswarmlistener.dockerflow.com\n for details on the \nDocker Flow\n stack.\n\n\nDeploying Docker Scaler\n\u00b6\n\n\nWe can now deploy the \nDocker Scaler\n stack:\n\n\ndocker network create -d overlay scaler\n\ndocker stack deploy \n\\\n\n    -c stacks/docker-scaler-basic-tutorial.yml \n\\\n\n    scaler\n\n\n\n\nThis stack defines a single \nDocker Scaler\n service:\n\n\n...\n\n  \nservices\n:\n\n    \nscaler\n:\n\n      \nimage\n:\n \nthomasjpfan/docker-scaler\n\n      \nenvironment\n:\n\n        \n-\n \nALERTMANAGER_ADDRESS=http://alertmanager:9093\n\n      \nvolumes\n:\n\n        \n-\n \n/var/run/docker.sock:/var/run/docker.sock\n\n      \nnetworks\n:\n\n        \n-\n \nscaler\n\n      \ndeploy\n:\n\n        \nplacement\n:\n\n            \nconstraints\n:\n \n[\nnode.role == manager\n]\n\n\n...\n\n\n\n\n\nThis definition constraints \nDocker Scaler\n to run on manager nodes and gives it access to the Docker socket, so that it can scale services in the cluster.\n\n\nDeploying Docker Flow Monitor and Alertmanager\n\u00b6\n\n\nThe next stack defines the \nDocker Flow Monitor\n and \nAlertmanager\n services. Before we deploy the stack, we defined our \nAlertmanager\n configuration as a Docker secret:\n\n\necho\n \n\"global:\n\n\n  slack_api_url: 'https://hooks.slack.com/services/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'\n\n\nroute:\n\n\n  group_by: [service, scale]\n\n\n  repeat_interval: 5m\n\n\n  group_interval: 5m\n\n\n  receiver: 'slack'\n\n\n  routes:\n\n\n  - match:\n\n\n      service: 'go-demo_main'\n\n\n      scale: up\n\n\n    receiver: 'scale-up'\n\n\n  - match:\n\n\n      service: 'go-demo_main'\n\n\n      scale: down\n\n\n    receiver: 'scale-down'\n\n\n  - match_re:\n\n\n      alertname: ^(scale_service|scale_node)\n$\n\n\n    group_by: [alertname, service]\n\n\n    receiver: 'slack-scaler'\n\n\n\nreceivers:\n\n\n  - name: 'slack'\n\n\n    slack_configs:\n\n\n      - send_resolved: true\n\n\n        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.service }} service is in danger!'\n\n\n        title_link: 'http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts'\n\n\n        text: '{{ .CommonAnnotations.summary }}'\n\n\n  - name: 'slack-scaler'\n\n\n    slack_configs:\n\n\n      - title: 'Docker Scaler triggered {{ .GroupLabels.alertname }}'\n\n\n        color: 'good'\n\n\n        title_link: 'http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts'\n\n\n        text: '{{ .CommonAnnotations.summary }}'\n\n\n  - name: 'scale-up'\n\n\n    webhook_configs:\n\n\n      - send_resolved: false\n\n\n        url: 'http://scaler:8080/v1/scale-service?name=go-demo_main&delta=1'\n\n\n  - name: 'scale-down'\n\n\n    webhook_configs:\n\n\n      - send_resolved: false\n\n\n        url: 'http://scaler:8080/v1/scale-service?name=go-demo_main&delta=-1'\n\n\n\"\n \n|\n docker secret create alert_manager_config -\n\n\n\n\nThis configuration groups alerts by their \nservice\n and \nscale\n labels. The \nroutes\n section defines two \nmatch\n entries, that directs the \nscale\n up alerts to the \nscale-up\n receiver and \nscale\n down alerts to the \nscale-down\n reciever. The \nscale-up\n receiver sends a \nPOST\n request to the \ndocker-scaler\n service with \ndelta\n parameter set to \n1\n to scale up the service. Conversely, the \nscale-down\n receiver sends a \nPOST\n request with \ndelta\n parameter set to \n-1\n to scale down the service.\n\n\nNow we can deploy the monitor \nmonitor\n stack.\n\n\ndocker network create -d overlay monitor\n\n\nDOMAIN\n=\n$(\ndocker-machine ip swarm-1\n)\n \n\\\n\n    docker stack deploy \n\\\n\n    -c stacks/docker-flow-monitor-slack.yml \n\\\n\n    monitor\n\n\n\n\nThe \nalert-manager\n service is configured to read the \nalert_manager_config\n secret in the stack definition as follows:\n\n\n...\n\n  \nalert-manager\n:\n\n    \nimage\n:\n \nprom/alertmanager\n\n    \nnetworks\n:\n\n      \n-\n \nmonitor\n\n      \n-\n \nscaler\n\n    \nsecrets\n:\n\n      \n-\n \nalert_manager_config\n\n    \ncommand\n:\n \n-config.file=/run/secrets/alert_manager_config -storage.path=/alertmanager\n\n\n...\n\n\n\n\n\nWith access to the \nscaler\n network, \nalert-manager\n can send scaling requests to the \nscaler\n service. For information about the Docker Flow Monitor stack can be found in its \ndocumentation\n.\n\n\nLet us confirm that the \nmonitor\n stack is up and running:\n\n\ndocker stack ps monitor\n\n\n\n\nPlease wait a few moments for all the replicas to have the status \nrunning\n. After the \nmonitor\n stack is up and running, we can start deploying the \ngo-demo\n service!\n\n\nDeploying Instrumented Service\n\u00b6\n\n\nThe \ngo-demo\n service already exposes response time metrics with labels for \nDocker Flow Monitor\n to scrape. We can deploy the service to be scaled based on the response time metrics:\n\n\ndocker stack deploy \n\\\n\n    -c stacks/go-demo-instrument-alert-short.yml \n\\\n\n    go-demo\n\n\n\n\nThe full stack definitino can be found at \ngo-demo-instrument-alert-short.yml\n. We will focus on the service labels for the \ngo-demo\n service relating to scaling and alerting:\n\n\nmain\n:\n\n  \n...\n\n  \ndeploy\n:\n\n    \n...\n\n    \nlabels\n:\n\n      \n...\n\n      \n- com.df.scaleMin=2\n\n      \n- com.df.scaleMax=4\n\n      \n- com.df.alertName.1=mem_limit\n\n      \n- com.df.alertIf.1=@service_mem_limit:0.8\n\n      \n- com.df.alertFor.1=5m\n\n      \n- com.df.alertName.2=resp_time_above\n\n      \n- com.df.alertIf.2=@resp_time_above:0.1,5m,0.99\n\n      \n- com.df.alertName.3=resp_time_below\n\n      \n- com.df.alertIf.3=@resp_time_below:0.025,5m,0.75\n\n    \n...\n\n\n\nThe \nscaleMin\n and \nscaleMax\n labels are used by \nDocker Scaler\n to bound the number replicas for the \ngo-main\n service. The \nalertName\n, \nalertIf\n and \nalertFor\n labels uses the \nAlertIf Parameter Shortcuts\n for creating full Prometheus expressions that translate into alerts. We can view the alerts generated by these labels:\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nDocker Flow Monitor translates the alert labeled \nresp_time_above\n into an alert called \ngodemo_main_resp_time_above\n with the following definition:\n\n\nALERT godemo_main_resp_tim_eabove\n  IF sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.1\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) < 0.99\n  LABELS {receiver=\"system\", scale=\"up\", service=\"go-demo_main\"}\n  ANNOTATIONS {summary=\"Response time of the service go-demo_main is above 0.1\"}\n\n\n\n\nThis alert is triggered when the response times of the \n0.1\n seconds bucket is above 99% for over five minutes. Notice that the alert is labeled with \nscale=up\n to comminucate to the \nAlertmanager\n that the \ngo-demo_main\n service should be scaled up.\n\n\nSimiliarly, the alert labeled \nresp_time_below\n is translated into an alert called \ngodemo_main_resp_time_below\n. It is labeled with \nscale=down\n to trigger a de-scaling event:\n\n\nALERT godemo_main_resp_time_below\n  IF sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.025\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) > 0.75\n  LABELS {receiver=\"system\", scale=\"down\", service=\"go-demo_main\"}\n  ANNOTATIONS {summary=\"Response time of the service go-demo_main is below 0.025\"}\n\n\n\n\nLet's confirm that the go-demo stack is up-and-running:\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nThere should be three replicas of the \ngo-demo_main\n service and one replica of the \ngo-demo_db\n service. Please wait for all replicas to be up and running.\n\n\nWe can confirm that \nDocker Flow Monitor\n is monitoring the \ngo-demo\n replicas:\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/targets\"\n\n\n\n\n\nThere should be two or three targets depending on whether Prometheus already sent the alert to de-scale the service.\n\n\nAutomatically Scaling Services\n\u00b6\n\n\nLet's go back to the Prometheus' alert screen:\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nBy this time, the \ngodemo_main_resp_time_below\n alert should be red since the \ngo-demo\n service has a response faster than twenty-five milliseconds limit we set. The Alertmanager recieves this alert, groups by the \nservice\n and \nscale\n labels and sends a \nPOST\n request to the \ndocker-scaler\n service with parameters \nservice=go-demo_main&delta=-1\n.\n\n\nLet's look at the logs of \ndocker-scaler\n:\n\n\ndocker service logs scaler_scaler\n\n\n\n\nThere should be a log message that states \ngo-demo_main was scaled from 3 to 2 replicas\n. We can check that this happened:\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nThe output should be similar to the following:\n\n\nNAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE         ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running 2 minutes ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running 3 minutes ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running 2 minutes ago\n\n\n\n\nPlease visit the \n#df-monitor-tests\n channel inside \ndevops20.slack.com\n and you should see a Slack notification stating that \ngo-demo_main could not be scaled\n. If this is your first visit to \ndevops20\n on Slack, you'll have to register through \nslack.devops20toolkit.com\n.\n\n\nLet's see what happens when response times of the service becomes too high by sending requests that will result in high response times:\n\n\nfor\n i in \n{\n1\n..30\n}\n;\n \ndo\n\n    \nDELAY\n=\n$\n[\n \n$RANDOM\n % \n6000\n \n]\n\n    curl \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/demo/hello?delay=\n$DELAY\n\"\n\n\ndone\n\n\n\n\n\nLet's look at the alerts:\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nThe \ngodemo_main_resp_time_above\n turned red indicating that the threshold is reached. \nAlertmanager\n receives the alert, sends a \nPOST\n request to the \ndocker-scaler\n service, and \ndocker-scaler\n scales \ngo-demo\n up by one. Let's look at the logs of \ndocker-scaler\n:\n\n\ndocker service logs scaler_docker-scaler\n\n\n\n\nThere should be a log message that states \ngo-demo_main was scaled from 2 to 3 replicas\n. This message is also sent through Slack to notify us of this scaling event.\n\n\nWe can confirm that the number of replicas indeed scaled to three by querying the stack processes:\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nThe output should look similar to the following:\n\n\nNAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE             ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running about an hour ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running about an hour ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running about an hour ago\ngo-demo_main.3 vfarcic/go-demo:latest swarm-1 Running       Running 42 seconds ago\n\n\n\n\nWhat Now?\n\u00b6\n\n\nYou saw a simple example of a system that automatically scales and de-scales services. Feel free to add additional metrics and services to this self-adapting system to customize it to your needs.\n\n\nPlease remove the demo cluster we created and free your resources:\n\n\ndocker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "Service Scaling"
        },
        {
            "location": "/service-scale/#auto-scaling-with-docker-scaler-and-instrumented-metrics",
            "text": "Docker Scaler  provides an alternative to using Jenkins for service scaling shown in Docker Flow Monitor's  auto-scaling tutorial . In this tutorial, we will construct a system that will scale a service based on response time. The following is an overview of the triggered events in our self-adapting system:   The  go-demo  service response times becomes too high.  Docker Flow Monitor  is querying the services' metrics, notices the high response times, and alerts the  Alertmanager .  The Alertmanager is configured to forward the alert to  Docker Scaler .  Docker Scaler  scales the service up.   This tutorial assumes you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.   Info  If you are a Windows user, please run all the examples from  Git Bash  (installed through  Docker for Windows ). Also, make sure that your Git client is configured to check out the code  AS-IS . Otherwise, Windows might change carriage returns to the Windows format.",
            "title": "Auto-Scaling With Docker Scaler And Instrumented Metrics"
        },
        {
            "location": "/service-scale/#setting-up-a-cluster",
            "text": "Info  Feel free to skip this section if you already have a Swarm cluster that can be used for this tutorial   We'll create a Swarm cluster consisting of three nodes created with Docker Machine.  git clone https://github.com/thomasjpfan/docker-scaler.git cd  docker-scaler\n\n./scripts/ds-swarm.sh eval   $( docker-machine env swarm-1 )   We cloned the  thomasjpfan/docker-scaler  respository. It contains all the scripts and stack files we will use throughout this tutorial. Next, we executed the  ds-swarm.sh  script that created the cluster. Finally, we used the  eval  command to tell our local Docker client to use the remote Docker Engine  swarm-1 .",
            "title": "Setting Up A Cluster"
        },
        {
            "location": "/service-scale/#deploying-docker-flow-proxy-dfp-and-docker-flow-swarm-listener-dfsl",
            "text": "For convenience, we will use  Docker Flow Proxy  and  Docker Flow Swarm Listener  to get a single access point to the cluster.  docker network create -d overlay proxy\n\ndocker stack deploy  \\ \n    -c stacks/docker-flow-proxy-mem.yml  \\ \n    proxy  Please visit  proxy.dockerflow.com  and  swarmlistener.dockerflow.com  for details on the  Docker Flow  stack.",
            "title": "Deploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)"
        },
        {
            "location": "/service-scale/#deploying-docker-scaler",
            "text": "We can now deploy the  Docker Scaler  stack:  docker network create -d overlay scaler\n\ndocker stack deploy  \\ \n    -c stacks/docker-scaler-basic-tutorial.yml  \\ \n    scaler  This stack defines a single  Docker Scaler  service:  ... \n   services : \n     scaler : \n       image :   thomasjpfan/docker-scaler \n       environment : \n         -   ALERTMANAGER_ADDRESS=http://alertmanager:9093 \n       volumes : \n         -   /var/run/docker.sock:/var/run/docker.sock \n       networks : \n         -   scaler \n       deploy : \n         placement : \n             constraints :   [ node.role == manager ]  ...   This definition constraints  Docker Scaler  to run on manager nodes and gives it access to the Docker socket, so that it can scale services in the cluster.",
            "title": "Deploying Docker Scaler"
        },
        {
            "location": "/service-scale/#deploying-docker-flow-monitor-and-alertmanager",
            "text": "The next stack defines the  Docker Flow Monitor  and  Alertmanager  services. Before we deploy the stack, we defined our  Alertmanager  configuration as a Docker secret:  echo   \"global:    slack_api_url: 'https://hooks.slack.com/services/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'  route:    group_by: [service, scale]    repeat_interval: 5m    group_interval: 5m    receiver: 'slack'    routes:    - match:        service: 'go-demo_main'        scale: up      receiver: 'scale-up'    - match:        service: 'go-demo_main'        scale: down      receiver: 'scale-down'    - match_re:        alertname: ^(scale_service|scale_node) $      group_by: [alertname, service]      receiver: 'slack-scaler'  receivers:    - name: 'slack'      slack_configs:        - send_resolved: true          title: '[{{ .Status | toUpper }}] {{ .GroupLabels.service }} service is in danger!'          title_link: 'http:// $( docker-machine ip swarm-1 ) /monitor/alerts'          text: '{{ .CommonAnnotations.summary }}'    - name: 'slack-scaler'      slack_configs:        - title: 'Docker Scaler triggered {{ .GroupLabels.alertname }}'          color: 'good'          title_link: 'http:// $( docker-machine ip swarm-1 ) /monitor/alerts'          text: '{{ .CommonAnnotations.summary }}'    - name: 'scale-up'      webhook_configs:        - send_resolved: false          url: 'http://scaler:8080/v1/scale-service?name=go-demo_main&delta=1'    - name: 'scale-down'      webhook_configs:        - send_resolved: false          url: 'http://scaler:8080/v1/scale-service?name=go-demo_main&delta=-1'  \"   |  docker secret create alert_manager_config -  This configuration groups alerts by their  service  and  scale  labels. The  routes  section defines two  match  entries, that directs the  scale  up alerts to the  scale-up  receiver and  scale  down alerts to the  scale-down  reciever. The  scale-up  receiver sends a  POST  request to the  docker-scaler  service with  delta  parameter set to  1  to scale up the service. Conversely, the  scale-down  receiver sends a  POST  request with  delta  parameter set to  -1  to scale down the service.  Now we can deploy the monitor  monitor  stack.  docker network create -d overlay monitor DOMAIN = $( docker-machine ip swarm-1 )   \\ \n    docker stack deploy  \\ \n    -c stacks/docker-flow-monitor-slack.yml  \\ \n    monitor  The  alert-manager  service is configured to read the  alert_manager_config  secret in the stack definition as follows:  ... \n   alert-manager : \n     image :   prom/alertmanager \n     networks : \n       -   monitor \n       -   scaler \n     secrets : \n       -   alert_manager_config \n     command :   -config.file=/run/secrets/alert_manager_config -storage.path=/alertmanager  ...   With access to the  scaler  network,  alert-manager  can send scaling requests to the  scaler  service. For information about the Docker Flow Monitor stack can be found in its  documentation .  Let us confirm that the  monitor  stack is up and running:  docker stack ps monitor  Please wait a few moments for all the replicas to have the status  running . After the  monitor  stack is up and running, we can start deploying the  go-demo  service!",
            "title": "Deploying Docker Flow Monitor and Alertmanager"
        },
        {
            "location": "/service-scale/#deploying-instrumented-service",
            "text": "The  go-demo  service already exposes response time metrics with labels for  Docker Flow Monitor  to scrape. We can deploy the service to be scaled based on the response time metrics:  docker stack deploy  \\ \n    -c stacks/go-demo-instrument-alert-short.yml  \\ \n    go-demo  The full stack definitino can be found at  go-demo-instrument-alert-short.yml . We will focus on the service labels for the  go-demo  service relating to scaling and alerting:  main : \n   ... \n   deploy : \n     ... \n     labels : \n       ... \n       - com.df.scaleMin=2 \n       - com.df.scaleMax=4 \n       - com.df.alertName.1=mem_limit \n       - com.df.alertIf.1=@service_mem_limit:0.8 \n       - com.df.alertFor.1=5m \n       - com.df.alertName.2=resp_time_above \n       - com.df.alertIf.2=@resp_time_above:0.1,5m,0.99 \n       - com.df.alertName.3=resp_time_below \n       - com.df.alertIf.3=@resp_time_below:0.025,5m,0.75 \n     ...  \nThe  scaleMin  and  scaleMax  labels are used by  Docker Scaler  to bound the number replicas for the  go-main  service. The  alertName ,  alertIf  and  alertFor  labels uses the  AlertIf Parameter Shortcuts  for creating full Prometheus expressions that translate into alerts. We can view the alerts generated by these labels:  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   Docker Flow Monitor translates the alert labeled  resp_time_above  into an alert called  godemo_main_resp_time_above  with the following definition:  ALERT godemo_main_resp_tim_eabove\n  IF sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.1\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) < 0.99\n  LABELS {receiver=\"system\", scale=\"up\", service=\"go-demo_main\"}\n  ANNOTATIONS {summary=\"Response time of the service go-demo_main is above 0.1\"}  This alert is triggered when the response times of the  0.1  seconds bucket is above 99% for over five minutes. Notice that the alert is labeled with  scale=up  to comminucate to the  Alertmanager  that the  go-demo_main  service should be scaled up.  Similiarly, the alert labeled  resp_time_below  is translated into an alert called  godemo_main_resp_time_below . It is labeled with  scale=down  to trigger a de-scaling event:  ALERT godemo_main_resp_time_below\n  IF sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.025\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) > 0.75\n  LABELS {receiver=\"system\", scale=\"down\", service=\"go-demo_main\"}\n  ANNOTATIONS {summary=\"Response time of the service go-demo_main is below 0.025\"}  Let's confirm that the go-demo stack is up-and-running:  docker stack ps -f desired-state = running go-demo  There should be three replicas of the  go-demo_main  service and one replica of the  go-demo_db  service. Please wait for all replicas to be up and running.  We can confirm that  Docker Flow Monitor  is monitoring the  go-demo  replicas:  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/targets\"   There should be two or three targets depending on whether Prometheus already sent the alert to de-scale the service.",
            "title": "Deploying Instrumented Service"
        },
        {
            "location": "/service-scale/#automatically-scaling-services",
            "text": "Let's go back to the Prometheus' alert screen:  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   By this time, the  godemo_main_resp_time_below  alert should be red since the  go-demo  service has a response faster than twenty-five milliseconds limit we set. The Alertmanager recieves this alert, groups by the  service  and  scale  labels and sends a  POST  request to the  docker-scaler  service with parameters  service=go-demo_main&delta=-1 .  Let's look at the logs of  docker-scaler :  docker service logs scaler_scaler  There should be a log message that states  go-demo_main was scaled from 3 to 2 replicas . We can check that this happened:  docker stack ps -f desired-state = running go-demo  The output should be similar to the following:  NAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE         ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running 2 minutes ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running 3 minutes ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running 2 minutes ago  Please visit the  #df-monitor-tests  channel inside  devops20.slack.com  and you should see a Slack notification stating that  go-demo_main could not be scaled . If this is your first visit to  devops20  on Slack, you'll have to register through  slack.devops20toolkit.com .  Let's see what happens when response times of the service becomes too high by sending requests that will result in high response times:  for  i in  { 1 ..30 } ;   do \n     DELAY = $ [   $RANDOM  %  6000   ] \n    curl  \"http:// $( docker-machine ip swarm-1 ) /demo/hello?delay= $DELAY \"  done   Let's look at the alerts:  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   The  godemo_main_resp_time_above  turned red indicating that the threshold is reached.  Alertmanager  receives the alert, sends a  POST  request to the  docker-scaler  service, and  docker-scaler  scales  go-demo  up by one. Let's look at the logs of  docker-scaler :  docker service logs scaler_docker-scaler  There should be a log message that states  go-demo_main was scaled from 2 to 3 replicas . This message is also sent through Slack to notify us of this scaling event.  We can confirm that the number of replicas indeed scaled to three by querying the stack processes:  docker stack ps -f desired-state = running go-demo  The output should look similar to the following:  NAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE             ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running about an hour ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running about an hour ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running about an hour ago\ngo-demo_main.3 vfarcic/go-demo:latest swarm-1 Running       Running 42 seconds ago",
            "title": "Automatically Scaling Services"
        },
        {
            "location": "/service-scale/#what-now",
            "text": "You saw a simple example of a system that automatically scales and de-scales services. Feel free to add additional metrics and services to this self-adapting system to customize it to your needs.  Please remove the demo cluster we created and free your resources:  docker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "What Now?"
        },
        {
            "location": "/aws-node-scale/",
            "text": "AWS Node Scaling\n\u00b6\n\n\nWork in progress.\n\n\nSetting Up An AWS Cluster\n\u00b6\n\n\nDeploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)\n\u00b6\n\n\nDeploying Docker Flow Monitor and Alertmanager\n\u00b6\n\n\nDeploying Instrumented Service\n\u00b6\n\n\nAutomatically Scaling Nodes\n\u00b6\n\n\nWhat Now?\n\u00b6",
            "title": "AWS Node Scaling"
        },
        {
            "location": "/aws-node-scale/#aws-node-scaling",
            "text": "Work in progress.",
            "title": "AWS Node Scaling"
        },
        {
            "location": "/aws-node-scale/#setting-up-an-aws-cluster",
            "text": "",
            "title": "Setting Up An AWS Cluster"
        },
        {
            "location": "/aws-node-scale/#deploying-docker-flow-proxy-dfp-and-docker-flow-swarm-listener-dfsl",
            "text": "",
            "title": "Deploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)"
        },
        {
            "location": "/aws-node-scale/#deploying-docker-flow-monitor-and-alertmanager",
            "text": "",
            "title": "Deploying Docker Flow Monitor and Alertmanager"
        },
        {
            "location": "/aws-node-scale/#deploying-instrumented-service",
            "text": "",
            "title": "Deploying Instrumented Service"
        },
        {
            "location": "/aws-node-scale/#automatically-scaling-nodes",
            "text": "",
            "title": "Automatically Scaling Nodes"
        },
        {
            "location": "/aws-node-scale/#what-now",
            "text": "",
            "title": "What Now?"
        },
        {
            "location": "/feedback-and-contribution/",
            "text": "Feedback and Contribution\n\u00b6\n\n\nThe \nDocker Scaler\n project welcomes, and depends, on contributions from developers and users in the open source community. Contributions can be made in a number of ways, a few examples are:\n\n\n\n\nCode patches or new features via pull requests\n\n\nDocumentation improvements\n\n\nBug reports and patch reviews\n\n\n\n\nReporting an Issue\n\u00b6\n\n\nFeel fee to \ncreate a new issue\n. Include as much detail as you can.\n\n\nIf an issue is a bug, please provide steps to reproduce it.\n\n\nIf an issue is a request for a new feature, please specify the use-case behind it.\n\n\nDiscussion\n\u00b6\n\n\nContributing To The Project\n\u00b6",
            "title": "Feedback and Contribution"
        },
        {
            "location": "/feedback-and-contribution/#feedback-and-contribution",
            "text": "The  Docker Scaler  project welcomes, and depends, on contributions from developers and users in the open source community. Contributions can be made in a number of ways, a few examples are:   Code patches or new features via pull requests  Documentation improvements  Bug reports and patch reviews",
            "title": "Feedback and Contribution"
        },
        {
            "location": "/feedback-and-contribution/#reporting-an-issue",
            "text": "Feel fee to  create a new issue . Include as much detail as you can.  If an issue is a bug, please provide steps to reproduce it.  If an issue is a request for a new feature, please specify the use-case behind it.",
            "title": "Reporting an Issue"
        },
        {
            "location": "/feedback-and-contribution/#discussion",
            "text": "",
            "title": "Discussion"
        },
        {
            "location": "/feedback-and-contribution/#contributing-to-the-project",
            "text": "",
            "title": "Contributing To The Project"
        },
        {
            "location": "/license/",
            "text": "Docker Scaler License (MIT)\n\u00b6\n\n\nCopyright \u00a9 2017 Thomas Fan\n\n\nThe MIT License (MIT)\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
            "title": "License"
        },
        {
            "location": "/license/#docker-scaler-license-mit",
            "text": "Copyright \u00a9 2017 Thomas Fan  The MIT License (MIT)  Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
            "title": "Docker Scaler License (MIT)"
        }
    ]
}